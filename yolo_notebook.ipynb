{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    Lambda,\n",
    "    MaxPool2D,\n",
    "    LeakyReLU,\n",
    "    Concatenate,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization)\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_STRIDES                = [8, 16, 32]\n",
    "YOLO_IOU_LOSS_THRESH        = 0.5\n",
    "YOLO_ANCHOR_PER_SCALE       = 3\n",
    "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
    "YOLO_INPUT_SIZE             = 416\n",
    "YOLO_ANCHORS                = [[[10,  13], [16,   30], [33,   23]],\n",
    "                               [[30,  61], [62,   45], [59,  119]],\n",
    "                               [[116, 90], [156, 198], [373, 326]]]\n",
    "\n",
    "STRIDES         = np.array(YOLO_STRIDES)\n",
    "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.region_shape_attributes = df.region_shape_attributes.apply(literal_eval)\n",
    "le = LabelEncoder()\n",
    "df.name = le.fit_transform(df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 416\n",
    "CLASSES = len(le.classes_)\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone of YoloV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(BatchNormalization):\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n",
    "\n",
    "\n",
    "def DarknetConv(x, filters, size, downsample=False, activate=True, bn=True):\n",
    "\n",
    "    if downsample:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "        padding = 'valid'\n",
    "        strides = 2\n",
    "    else:\n",
    "        padding = 'same'\n",
    "        strides = 1\n",
    "\n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding, use_bias=not bn,\n",
    "               kernel_regularizer=l2(0.0005),\n",
    "               kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "               bias_initializer=tf.constant_initializer(0.))(x)\n",
    "\n",
    "    if bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activate:\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "\n",
    "    short_cut = x\n",
    "    x = DarknetConv(x, filters=filters//2, size=1)\n",
    "    x = DarknetConv(x, filters=filters, size=3)\n",
    "    x = Add()([short_cut, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters=filters, size=3, downsample=True)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Darknet(name=None):\n",
    "\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, filters=32, size=3)\n",
    "    x = DarknetBlock(x, 64, 2)\n",
    "    x = DarknetBlock(x, 128, 2)\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "\n",
    "    return Model(inputs, (x_36, x_61, x), name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YoloV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "\n",
    "\n",
    "def YoloOutput(classes=80, masks=None, strides=None):\n",
    "    def yolo_output(x):\n",
    "\n",
    "        batch_size, output_size = tf.shape(x)[:2]\n",
    "        x_output = tf.reshape(x, (-1, output_size, output_size,\n",
    "                                  3, 5 + classes))\n",
    "\n",
    "        x_dxdy = x_output[:, :, :, :, 0:2]\n",
    "        x_dwdh = x_output[:, :, :, :, 2:4]\n",
    "        x_conf = x_output[:, :, :, :, 4:5]\n",
    "        x_prob = x_output[:, :, :, :, 5:]\n",
    "\n",
    "        # Draw the grid\n",
    "        y = tf.range(output_size, dtype=tf.int32)\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        y = tf.tile(y, [1, output_size])\n",
    "        x = tf.range(output_size, dtype=tf.int32)\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        x = tf.tile(x, [output_size, 1])\n",
    "\n",
    "        xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]],\n",
    "                            axis=-1)\n",
    "        xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :],\n",
    "                          [batch_size, 1, 1, 3, 1])\n",
    "        xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "        pred_xy = (tf.sigmoid(x_dxdy) + xy_grid) * strides\n",
    "        pred_wh = tf.exp(x_dwdh) * masks * strides\n",
    "\n",
    "        pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "        pred_conf = tf.sigmoid(x_conf)\n",
    "        pred_prob = tf.sigmoid(x_prob)\n",
    "\n",
    "        return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "    return yolo_output\n",
    "\n",
    "\n",
    "def YoloV3(size=None, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, 3], name='input')\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    l_output = DarknetConv(x, filters=3*(classes + 5),\n",
    "                           size=1, activate=False, bn=False)\n",
    "\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    m_output = DarknetConv(x, filters=3*(classes + 5),\n",
    "                           size=1, activate=False, bn=False)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    s_output = DarknetConv(x, filters=3*(classes + 5),\n",
    "                           size=1, activate=False, bn=False)\n",
    "\n",
    "    output_tensors = []\n",
    "    for i, output_tensor in enumerate([s_output, m_output, l_output]):\n",
    "        pred_tensor = YoloOutput(classes, masks=ANCHORS[i],\n",
    "                                 strides=STRIDES[i])(output_tensor)\n",
    "        if training:\n",
    "            output_tensors.append(output_tensor)\n",
    "        output_tensors.append(pred_tensor)\n",
    "\n",
    "    return Model(inputs, output_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, target_size, gt_boxes=None):\n",
    "    ih = iw = target_size\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_paded\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_paded, gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(bboxes1, bboxes2):\n",
    "\n",
    "    bboxes1_area = bboxes1[..., 2] * bboxes1[..., 3]\n",
    "    bboxes2_area = bboxes2[..., 2] * bboxes2[..., 3]\n",
    "\n",
    "    bboxes1 = tf.concat([bboxes1[..., 0:2] - bboxes1[..., 2:4] * 0.5,\n",
    "                         bboxes1[..., 0:2] + bboxes1[..., 2:4] * 0.5], axis=-1)\n",
    "    bboxes2 = tf.concat([bboxes2[..., 0:2] - bboxes2[..., 2:4] * 0.5,\n",
    "                         bboxes2[..., 0:2] + bboxes2[..., 2:4] * 0.5], axis=-1)\n",
    "\n",
    "    inter_box = tf.concat([tf.maximum(bboxes1[..., 0:2], bboxes2[..., 0:2]),\n",
    "                           tf.minimum(bboxes1[..., 2:4], bboxes2[..., 2:4])],\n",
    "                          axis=-1)\n",
    "    inter_area = tf.maximum(\n",
    "        (inter_box[..., 2] - inter_box[..., 0]) * (inter_box[..., 3] - inter_box[..., 1]), 0.0)\n",
    "\n",
    "    union_area = bboxes1_area + bboxes2_area - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "\n",
    "def bbox_giou(bboxes1, bboxes2):\n",
    "\n",
    "    bboxes1_area = bboxes1[..., 2] * bboxes1[..., 3]\n",
    "    bboxes2_area = bboxes2[..., 2] * bboxes2[..., 3]\n",
    "\n",
    "    bboxes1 = tf.concat([bboxes1[..., 0:2] - bboxes1[..., 2:4] * 0.5,\n",
    "                         bboxes1[..., 0:2] + bboxes1[..., 2:4] * 0.5], axis=-1)\n",
    "    bboxes2 = tf.concat([bboxes2[..., 0:2] - bboxes2[..., 2:4] * 0.5,\n",
    "                         bboxes2[..., 0:2] + bboxes2[..., 2:4] * 0.5], axis=-1)\n",
    "\n",
    "    inter_box = tf.concat([tf.maximum(bboxes1[..., 0:2], bboxes2[..., 0:2]),\n",
    "                           tf.minimum(bboxes1[..., 2:4], bboxes2[..., 2:4])],\n",
    "                          axis=-1)\n",
    "    inter_area = tf.maximum(\n",
    "        (inter_box[..., 2] - inter_box[..., 0]) * (inter_box[..., 3] - inter_box[..., 1]), 0.0)\n",
    "\n",
    "    union_area = bboxes1_area + bboxes2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    g_box = tf.concat([tf.minimum(bboxes1[..., 0:2], bboxes2[..., 0:2]),\n",
    "                       tf.maximum(bboxes1[..., 2:4], bboxes2[..., 2:4])],\n",
    "                      axis=-1)\n",
    "    g_area = tf.maximum(\n",
    "        (g_box[..., 2] - g_box[..., 0]) * (g_box[..., 3] - g_box[..., 1]), 0.0)\n",
    "    return iou - (g_area - union_area) / g_area"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "m = YoloV3(INPUT_SIZE, CLASSES, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, df, num_classes, batch_size,\n",
    "                 input_size=416, loadimg=False, augment=False):\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.loadimg = loadimg\n",
    "        self.data_aug = augment\n",
    "\n",
    "        self.strides = STRIDES\n",
    "        self.anchors = ANCHORS\n",
    "        self.anchor_per_scale = 3\n",
    "        self.max_bbox_per_scale = 100\n",
    "        self.output_size = self.input_size // STRIDES\n",
    "\n",
    "        self.annotations = self.load_annotations(df, self.loadimg)\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def load_annotations(self, df, loadimg=False):\n",
    "\n",
    "        annotations = []\n",
    "        for img_path in df.img_path.unique():\n",
    "            tmp = []\n",
    "            for _, line in df[df.img_path == img_path].iterrows():\n",
    "                rsa = line['region_shape_attributes']\n",
    "                xmin = rsa['x']\n",
    "                ymin = rsa['y']\n",
    "                xmax = rsa['x'] + rsa['width']\n",
    "                ymax = rsa['y'] + rsa['height']\n",
    "                class_ = line['name']\n",
    "                tmp.append([xmin, ymin, xmax, ymax, class_])\n",
    "\n",
    "            annotations.append([img_path, tmp])\n",
    "        return annotations\n",
    "\n",
    "    def preprocess(self, annotaion):\n",
    "        image, bboxes = annotaion\n",
    "        bboxes = np.array(list(map(np.array, bboxes)))\n",
    "        image, bboxes = image_preprocess(np.copy(cv2.imread(image)),\n",
    "                                         target_size=self.input_size,\n",
    "                                         gt_boxes=np.copy(bboxes))\n",
    "\n",
    "        label = [np.zeros((self.output_size[i],\n",
    "                           self.output_size[i],\n",
    "                           self.anchor_per_scale,\n",
    "                           5 + self.num_classes)) for i in range(3)]\n",
    "        for bbox in bboxes:\n",
    "            bbox_coor = bbox[:4]\n",
    "            bbox_class_ind = bbox[4]\n",
    "\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float)\n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "            uniform_distribution = np.full(self.num_classes,\n",
    "                                           1.0 / self.num_classes)\n",
    "            deta = 0.01\n",
    "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
    "\n",
    "            bbox_xywh = np.concatenate(\n",
    "                [(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]],\n",
    "                axis=-1)\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / \\\n",
    "                self.strides[:, np.newaxis]\n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False\n",
    "            for i in range(3):\n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "\n",
    "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :],\n",
    "                                     anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "                iou_mask = iou_scale > 0.3\n",
    "\n",
    "                if np.any(iou_mask):\n",
    "                    xind, yind = np.floor(\n",
    "                        bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
    "\n",
    "                    label[i][yind, xind, iou_mask, :] = 0\n",
    "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
    "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    exist_positive = True\n",
    "\n",
    "            if not exist_positive:\n",
    "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
    "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
    "                xind, yind = np.floor(\n",
    "                    bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
    "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
    "\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        return image, label_sbbox, label_mbbox, label_lbbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'Dataset Generator with {self.num_samples} datapoints '\n",
    "                'in {self.num_batchs} batches')\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __next__(self):\n",
    "        batch_images = np.zeros((self.batch_size, self.input_size,\n",
    "                                 self.input_size, 3), dtype=np.float32)\n",
    "        batch_slabels = np.zeros(\n",
    "            (self.batch_size, self.output_size[0],\n",
    "             self.output_size[0], 3, 5 + self.num_classes),\n",
    "            dtype=np.float32)\n",
    "        batch_mlabels = np.zeros(\n",
    "            (self.batch_size, self.output_size[1],\n",
    "             self.output_size[1], 3, 5 + self.num_classes),\n",
    "            dtype=np.float32)\n",
    "        batch_llabels = np.zeros(\n",
    "            (self.batch_size, self.output_size[2],\n",
    "             self.output_size[2], 3, 5 + self.num_classes),\n",
    "            dtype=np.float32)\n",
    "\n",
    "        if self.batch_count < self.num_batchs:\n",
    "            for i in range(self.batch_size):\n",
    "                idx = self.batch_count * self.batch_size + i\n",
    "                if idx > self.num_samples:\n",
    "                    idx = idx - self.num_samples\n",
    "                annotation = self.annotations[idx]\n",
    "\n",
    "                image, slabel, mlabel, llabel = self.preprocess(annotation)\n",
    "                batch_images[i, ...] = image\n",
    "                batch_slabels[i, ...] = slabel\n",
    "                batch_mlabels[i, ...] = mlabel\n",
    "                batch_llabels[i, ...] = llabel\n",
    "\n",
    "            self.batch_count += 1\n",
    "            return batch_images, [batch_slabels, batch_mlabels, batch_llabels]\n",
    "        else:\n",
    "            self.batch_count = 0\n",
    "            np.random.shuffle(self.annotations)\n",
    "            raise StopIteration\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = Dataset(df, CLASSES, BATCH_SIZE, INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
